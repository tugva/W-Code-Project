{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "958457dc-7dc6-4cad-991f-32b1db57cfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oluşturulan DataFrame:\n",
      "    Kategori           Ürün  Fiyat\n",
      "0     Giyim          Kazak    300\n",
      "1     Giyim        T-shirt    180\n",
      "2  Ayakkabı       Sandalet    450\n",
      "3  Aksesuar           Küpe     50\n",
      "4  Ayakkabı  Spor Ayakkabı    700\n",
      "5     Giyim       Pantolon    400\n",
      "6  Aksesuar          Kolye    150\n",
      "7  Aksesuar          Yüzük     80\n",
      "8  Ayakkabı          Çizme    850\n",
      "9     Giyim          Ceket    900\n",
      "\n",
      "2. index'teki kategori: Ayakkabı\n",
      "\n",
      "2. index'teki ürün: Sandalet\n",
      "\n",
      "4. index'ten 9. index'e kadar olan veriler:\n",
      "    Kategori           Ürün  Fiyat\n",
      "4  Ayakkabı  Spor Ayakkabı    700\n",
      "5     Giyim       Pantolon    400\n",
      "6  Aksesuar          Kolye    150\n",
      "7  Aksesuar          Yüzük     80\n",
      "8  Ayakkabı          Çizme    850\n",
      "9     Giyim          Ceket    900\n",
      "\n",
      "1. index'ten 6. index'e kadar olan ürünler:\n",
      " 1          T-shirt\n",
      "2         Sandalet\n",
      "3             Küpe\n",
      "4    Spor Ayakkabı\n",
      "5         Pantolon\n",
      "6            Kolye\n",
      "Name: Ürün, dtype: object\n",
      "\n",
      "Giyim kategorisinde bulunan ürünler:\n",
      "   Kategori      Ürün  Fiyat\n",
      "0    Giyim     Kazak    300\n",
      "1    Giyim   T-shirt    180\n",
      "5    Giyim  Pantolon    400\n",
      "9    Giyim     Ceket    900\n",
      "\n",
      "Ayakkabı kategorisinde bulunan ürünler:\n",
      "    Kategori           Ürün  Fiyat\n",
      "2  Ayakkabı       Sandalet    450\n",
      "4  Ayakkabı  Spor Ayakkabı    700\n",
      "8  Ayakkabı          Çizme    850\n",
      "\n",
      "Aksesuar kategorisinde bulunan ürünler:\n",
      "    Kategori   Ürün  Fiyat\n",
      "3  Aksesuar   Küpe     50\n",
      "6  Aksesuar  Kolye    150\n",
      "7  Aksesuar  Yüzük     80\n",
      "\n",
      "Giyim kategorisinde fiyatı 300'den fazla olan ürünler:\n",
      "   Kategori      Ürün  Fiyat\n",
      "5    Giyim  Pantolon    400\n",
      "9    Giyim     Ceket    900\n",
      "\n",
      "Ayakkabı kategorisinde fiyatı 600'den az olan ürünler:\n",
      "    Kategori      Ürün  Fiyat\n",
      "2  Ayakkabı  Sandalet    450\n",
      "\n",
      "Aksesuar kategorisinde fiyatı 100'den fazla olan ürünler:\n",
      "    Kategori   Ürün  Fiyat\n",
      "6  Aksesuar  Kolye    150\n"
     ]
    }
   ],
   "source": [
    "#sozluk = {\"Kategori\": [\"Giyim\",\"Giyim\", \"Ayakkabı\",\"Aksesuar\",\"Ayakkabı\",\"Giyim\",\"Aksesuar\",\"Aksesuar\",\"Ayakkabı\",\"Giyim\"],\n",
    "    #\"Ürün\" : [\"Kazak\",\"T-shirt\",\"Sandalet\",\"Küpe\",\"Spor Ayakkabı\",\"Pantolon\",\"Kolye\",\"Yüzük\",\"Çizme\",\"Ceket\"],\n",
    "    #\"Fiyat\" : [300,180,450,50,700,400,150,80,850,900]}\n",
    "\n",
    "#Yukarıdaki sözlük DataFrame’e dönüştürülür. \n",
    "\n",
    "    #Yukarıdaki DataFrame için \n",
    "        #2.indexte bulunan kategori bulunur. (Sadece kategori bilgisi) \n",
    "        #2. indexte bulunan ürün bulunur. (Sadece ürün bilgisi) \n",
    "        #4.indexten 9.indexe kadar olan veriler bulunur. (Kategori,ürün,fiyat bilgisi beraber) \n",
    "        #1.indexten 6.indexe kadar olan ürünler bulunur. (Sadece ürün bilgisi) \n",
    "\n",
    "    #Yukarıdaki DataFrame için \n",
    "        #Giyim kategorisinde bulunan ürünler gösterilir. \n",
    "        #Ayakkabı kategorisinde bulunan ürünler gösterilir. \n",
    "        #Aksesuar kategorisinde bulunan ürünler gösterilir. \n",
    "\n",
    "    #Yukarıdaki DataFrame için \n",
    "        #Giyim kategorisinde fiyatı 300'den fazla olan ürünler gösterilir. \n",
    "        #Ayakkabı kategorisinde fiyatı 600'den az olan ürünler gösterilir. \n",
    "        #Aksesuar kategorisinde fiyatı 100'den fazla olan aksesuar gösterilir. \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sozluk = {\n",
    "    \"Kategori\": [\"Giyim\", \"Giyim\", \"Ayakkabı\", \"Aksesuar\", \"Ayakkabı\", \"Giyim\", \"Aksesuar\", \"Aksesuar\", \"Ayakkabı\", \"Giyim\"],\n",
    "    \"Ürün\": [\"Kazak\", \"T-shirt\", \"Sandalet\", \"Küpe\", \"Spor Ayakkabı\", \"Pantolon\", \"Kolye\", \"Yüzük\", \"Çizme\", \"Ceket\"],\n",
    "    \"Fiyat\": [300, 180, 450, 50, 700, 400, 150, 80, 850, 900]\n",
    "}\n",
    "#DataFrame oluşturma\n",
    "df = pd.DataFrame(sozluk)\n",
    "print(\"Oluşturulan DataFrame:\\n\", df)\n",
    "\n",
    "kategori_2 = df.loc[2, \"Kategori\"]\n",
    "print(\"\\n2. index'teki kategori:\", kategori_2)\n",
    "\n",
    "urun_2 = df.loc[2, \"Ürün\"]\n",
    "print(\"\\n2. index'teki ürün:\", urun_2)\n",
    "\n",
    "veriler_4_9 = df.loc[4:9]\n",
    "print(\"\\n4. index'ten 9. index'e kadar olan veriler:\\n\", veriler_4_9)\n",
    "\n",
    "urunler_1_6 = df.loc[1:6, \"Ürün\"]\n",
    "print(\"\\n1. index'ten 6. index'e kadar olan ürünler:\\n\", urunler_1_6)\n",
    "\n",
    "giyim_urunleri = df[df[\"Kategori\"] == \"Giyim\"]\n",
    "print(\"\\nGiyim kategorisinde bulunan ürünler:\\n\", giyim_urunleri)\n",
    "\n",
    "ayakkabi_urunleri = df[df[\"Kategori\"] == \"Ayakkabı\"]\n",
    "print(\"\\nAyakkabı kategorisinde bulunan ürünler:\\n\", ayakkabi_urunleri)\n",
    "\n",
    "aksesuar_urunleri = df[df[\"Kategori\"] == \"Aksesuar\"]\n",
    "print(\"\\nAksesuar kategorisinde bulunan ürünler:\\n\", aksesuar_urunleri)\n",
    "\n",
    "#Fiyat bazında filtreleme\n",
    "giyim_fiyat_300 = df[(df[\"Kategori\"] == \"Giyim\") & (df[\"Fiyat\"] > 300)]\n",
    "print(\"\\nGiyim kategorisinde fiyatı 300'den fazla olan ürünler:\\n\", giyim_fiyat_300)\n",
    "\n",
    "ayakkabi_fiyat_600 = df[(df[\"Kategori\"] == \"Ayakkabı\") & (df[\"Fiyat\"] < 600)]\n",
    "print(\"\\nAyakkabı kategorisinde fiyatı 600'den az olan ürünler:\\n\", ayakkabi_fiyat_600)\n",
    "\n",
    "aksesuar_fiyat_100 = df[(df[\"Kategori\"] == \"Aksesuar\") & (df[\"Fiyat\"] > 100)]\n",
    "print(\"\\nAksesuar kategorisinde fiyatı 100'den fazla olan ürünler:\\n\", aksesuar_fiyat_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b424a459-0c7a-4bd1-bb03-dd30cd6b8977",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:\\\\python\\\\WCode-Gelecek-Hayalim-Data-Science\\\\week7\\\\all_poems.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      8\u001b[0m dosyayolu\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mWCode-Gelecek-Hayalim-Data-Science\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mweek7\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mall_poems.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(dosyayolu)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39minfo())\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:\\\\python\\\\WCode-Gelecek-Hayalim-Data-Science\\\\week7\\\\all_poems.csv'"
     ]
    }
   ],
   "source": [
    "#Kaggle’dan bulunan bir veri seti üzerinde analiz ve görselleştirme çalışmaları yapılır.\n",
    "#Turkish Poems - data set\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dosyayolu=r\"E:\\python\\WCode-Gelecek-Hayalim-Data-Science\\week7\\all_poems.csv\"\n",
    "df = pd.read_csv(dosyayolu)\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df.isnull().sum())\n",
    "df.dropna(inplace=True) \n",
    "\n",
    "#Görselleştirme\n",
    "poet_counts = df['poet_name'].value_counts()  \n",
    "\n",
    "#Çubuk grafiği \n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x=poet_counts.index, y=poet_counts.values)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Şair Başına Düşen Şiir Sayısı')\n",
    "plt.xlabel('Şiir')\n",
    "plt.ylabel('Şiir Sayısı')\n",
    "plt.subplots_adjust(bottom=0.25) #alt boşluk için\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
